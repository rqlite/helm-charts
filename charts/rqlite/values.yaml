# Overrides for the chart name and its computed full name.
#
# In most cases these can be left as null, but if you want your resources to be prefixed
# with a different name than the release name, you can specify fullnameOverride to the
# desired prefix.
nameOverride: null
fullnameOverride: null


# Container image details for all nodes in the rqlite cluster. Applies to both voter
# nodes and read-only nodes (if enabled below).
image:
  repository: docker.io/rqlite/rqlite
  # Overrides the image tag whose default is the chart appVersion
  tag: null
  # Override the image pull policy. When undefined (as is default here), the field is
  # omitted from the pod specs, which causes K8s to use its fairly reasonable default
  # adaptive policy behavior.
  #
  # https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy
  pullPolicy: null
  # Optionally specify an array of imagePullSecrets. You must create any secrets
  # referenced here yourself in the same namespace.
  #
  # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  pullSecrets: []


# The number of voting nodes (as opposed to read-only nodes). Voting nodes are
# standard rqlite nodes and participate in the Raft consensus system.
#
# A single replica is the default for ease of use, but highly available deployments will
# need an odd number greater than 1 (typically 3).
#
# Removing nodes from an rqlite cluster requires more than just decreasing this value.
# See the "Scaling Voting Nodes" section of chart's README for details of the correct
# procedure.
replicaCount: 1


# Use a statically generated peers list instead of DNS-based discovery.
#
# This should only be used to recover a broken cluster that has lost quorum and can't
# start up properly by restoring the missing nodes. This could happen because, for
# example, you have lost the underlying block storage for the original nodes.
#
# See "Recovering From Permanent Loss of Quorum" in the chart's README for more
# information on how to use this setting as part of a recovery procedure.
useStaticPeers: false

# When enabled, a NetworkPolicy is created that restricts the inter-node raft port to
# only be accessible to other rqlite nodes in the cluster.
#
# This will only take effect if the Kubernetes cluster has a CNI plugin that implements
# NetworkPolicy (such as Calico).
#
# You will want to disable this if you require connectivity to the raft port from
# outside the cluster.
networkPolicy:
  enabled: true


# Pod requests and limits.
#
# https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  # Container limits not defined by default
  # limits: {}


# How to update the StatefulSets. This stanza is dropped in directly into the
# updateStrategy map of the StatefulSet. Helm templating is supported.
#
# https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
updateStrategy:
  type: RollingUpdate

# rqlited is given this amount of time to gracefully shutdown before SIGKILL occurs.
#
# You may need to increase this for large data sets or slow storage, because SQLite
# checkpoints the WAL to its database file on shutdown. The Kubelet issuing SIGKILL
# during this process would be undesirable.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
terminationGracePeriodSeconds: 15

# The pod-level security context.
#
# By default, all rqlite containers are run as non-root. rqlite isn't opinionated about
# the UID it runs under.
#
# https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
podSecurityContext:
  runAsUser: 10050
  runAsGroup: 10050
  fsGroup: 10050
  fsGroupChangePolicy: OnRootMismatch

# The container-level security context. Custom Linux capabilities, Seccomp profiles,
# SELinux labels, etc. may be defined here.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
securityContext: {}


# Configures the K8s Service Account for rqlite pods. rqlite doesn't use the K8s API, so
# by default a service account is neither created nor used. However, if you're using
# automatic backup/restore (see config.backup below) and the chart is deployed on EKS in
# AWS, you will probably want to use an IAM Role for Service Accounts (IRSA):
#
# https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html
#
# IRSA allows rqlite to access the S3 bucket for backup/restore without configuring static
# credentials.
serviceAccount:
  # If true, the chart will create a ServiceAccount resource, in which case the "name"
  # must be set below otherwise the chart will error. Set this to false if rqlite should
  # not use service account (the default), or if you're precreating your own
  # ServiceAccount (for example because you used Terraform to create an IRSA role and
  # corresponding K8s Service Account).
  create: false
  # The name of the service account to use for rqlite pods. If this is empty, then
  # no service account will be used by rqlite pods.
  name: ""
  # Custom annotations to add to the ServiceAccount
  annotations: {}


# Persistent Volume configuration.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
persistence:
  # Setting this to false will store data on an empheral volume, which will be lost when
  # the pod is cycled. Obviously this is only useful for testing or limited use cases.
  enabled: true
  # Labels for the persistent volume claim
  labels: {}
  # If null, the default storage class will be used
  storageClassName: null
  size: 10Gi
  accessModes:
    - ReadWriteOnce

# Node labels for pod assignment. Helm templating is supported.
#
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
nodeSelector: {}

# Node tolerations. Helm templating is supported.
#
# https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
tolerations: []

# Node affinity/anti-affinity. Helm templating is supported.
#
# https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/
#
# The default chart value ensures pods are only scheduled on nodes with architectures
# supported by rqlite's official container image.
#
# If you've build your own custom rqlite image for other architectures, then in addition
# to updating the image map above, you will also need to replace the affinity field to
# override the chart default.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
          - key: "kubernetes.io/arch"
            operator: In
            values:
              - amd64
              - "386"
              - arm
              - arm64

# Topology spread constraints influence how pods are scheduled across the cluster.
#
# Helm templating is supported per the commented example below.
#
# https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
topologySpreadConstraints: []
  # - topologyKey: topology.kubernetes.io/zone
  #   maxSkew: 1
  #   whenUnsatisfiable: ScheduleAnyway
  #   labelSelector:
  #     matchLabels:
  #       app.kubernetes.io/name: '{{ template "rqlite.name" . }}'
  #       app.kubernetes.io/instance: '{{ .Release.Name }}'


# If pod disruption is empty (as is default below), it will ensure quorum can always be
# met by using replicaCount (above) and allowing a maximum of N - (N/2 + 1) pods being
# unavailable, but always tolerates at least 1 node down for the single replica case
# (where downtime is implied to be acceptable).
#
# https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
#
# This value is *not* inherited by read-only nodes, but can be defined separately (see
# "readonly" below).
podDisruptionBudget: {}

# Additional labels for the rqlite pods.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
podLabels: {}

# Annotations for the rqlite pods.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
podAnnotations: {}

# Additional command line arguments to pass to rqlited.
#
# By default, foreign key constraints are enabled.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
extraArgs:
  - -fk=true

# Additional environment variables added to each rqlite pod.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
extraEnv: []
# - name: SOME_VAR
#   value: 'some value'

# Additional arbitrary user-defined text-based config files added to each rqlite pod.
#
# The contents are stored in a Secret. The files are mounted within the rqlite pod under
# /config/extra and the filename corresponds to the map key, and the value contains the
# literal content of the files as a string. (Consequently, binary data isn't supported
# here.)
#
# This can be used to support rqlite features not abstracted by the "config" section of
# the Helm chart (below), and would typically be combined with extraArgs and/or extraEnv
# above.
extraFiles: {}


# Readiness probe to determine if the pod is ready to receive traffic. Helm templating is
# supported.
#
# https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
#
# When rqlite user auth is enabled (see config.users below), an internal user will be
# automatically created (with a random password) for health probes. The credentials
# for this generated user are accessible within a template using .Release.rqlite.probeUser
# and .Release.rqlite.probePassword. As a convenience for probes using HTTP basic auth,
# the value .Release.rqlite.probeBasicAuthHeader contains a ready-made value for the
# Authorization header.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
readinessProbe:
  periodSeconds: 5
  timeoutSeconds: 2
  initialDelaySeconds: 3
  httpGet:
    # Set scheme to either HTTPS or HTTP based on whether TLS is enabled in the config
    # section below.
    scheme: '{{ .Values.config.tls.client.enabled | ternary "HTTPS" "HTTP" }}'
    path: /readyz
    port: http
    # Here we include the header for HTTP basic auth. If user authorization isn't enabled
    # (i.e. config.users below is empty), then the Authorization header will just be the
    # empty string, but this is harmless.
    #
    # This does mean the randomly generated probe user credentials are visible in
    # cleartext in the StatefulSet manifest (because Kubernetes doesn't support sourcing
    # probe headers from Secrets), but given how severely limited this user's privileges
    # are, it's deemed an acceptable compromise.
    httpHeaders:
      - name: Authorization
        value: '{{ empty .Values.config.users | ternary "" .Release.rqlite.probeBasicAuthHeader }}'

# Startup probe used to gate liveness probes. Not used by default as readiness probe is
# usually sufficient.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
startupProbe: {}

# Liveness probe used by K8s to decide if a pod should be forcefully restarted.
#
# Be very cautious about enabling this. Liveness probes are a notorious footgun.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
livenessProbe: {}


# The Kubernetes Service that clients can connect to.
#
# This value is inherited by read-only nodes but may be overridden (see "readonly" below).
service:
  type: ClusterIP
  # Use K8s-default IP family
  ipFamilyPolicy: null
  ipFamilies: []
  # Leave null to automatically generate a ClusterIP
  clusterIP: null
  # If type is NodePort or LoadBalancer, this may be defined to set an explicit node port.
  # Note that this particular field is not inherited by the read-pool (if enabled) because
  # uniqueness is required.
  nodePort: null
  # Service port defaults to port 80 when config.tls.http.enabled is false, or 443
  # otherwise. But you can override the default choice here.
  port: null
  # A custom node port can be specified if type is NodePort or LoadBalancer
  # nodePort: 31004
  annotations: {}


# An optional Kubernetes Ingress for the rqlite client HTTP(S) API.
#
# This value is *not* inherited by read-only nodes, but can be defined separately (see
# "readonly" below).
ingress:
  # If true, the Ingress resource will be created
  enabled: false
  # If null, the default ingress class is used
  ingressClassName: null
  # FQDNs that the Ingress will respond to. If not defined, no host will be specified in
  # the path definition, which means the path will match any DNS name mapped to the
  # ingress.
  hosts: []
  # rqlite doesn't natively support subpathing, so if you want to use a non-root
  # path you will need to annotate the Ingress according to your ingress controller
  # to rewrite the path. For example, for ingress-nginx, see
  # https://kubernetes.github.io/ingress-nginx/examples/rewrite/
  path: /
  # If using path rewriting with custom ingress annotations, set to ImplementationSpecific
  pathType: Prefix
  # Custom annotations for the Ingress resource. Note that if config.client.tls.enabled is
  # true, you will need to add the appropriate annotation for your ingress to have it
  # connect to the backend over HTTPS. (As a convenience, the chart takes care of this
  # for ingress-nginx natively, but if you use a different ingress controller, you'll need
  # to set this yourself.)
  annotations: {}
  # Additional custom labels for the Ingress
  extraLabels: {}
  # If using a TLS certificate that isn't the ingress proxy's default, this references a
  # Kubernetes Secret that contains the certificate, which must be manually created in the
  # same namespace as rqlite. (Automatic certificate generation via cert-manager may be
  # supported in the future.)
  tls: []
  #   - secretName: rqlite-server-tls
  #     hosts:
  #       - rqlite.example.com


# rqlite supports a separate pool of read-only replicas, which can service read queries
# with a read-consistency of none. See https://rqlite.io/docs/clustering/read-only-nodes/
#
# When a read-only node receives a request with any consistency level *other* than none,
# it will forward the request to the cluster's current leader node. So be careful,
# because failing to set a read-consistency of none will rather defeat the purpose of a
# dedicated read-only node pool. (Note that the default consistency level is "weak" so
# this does need to be explicitly set.)
#
# See also https://rqlite.io/docs/api/read-consistency/
#
# When readonly.replicaCount below is set to a value greater than 0, the Kubernetes
# resources for the read-only pool will be created, which includes a dedicated K8s
# Service. You can also create an Ingress for the read-only pool.
#
# Any top-level key above that's documented as applying to read-only nodes can be
# defined/overridden in this section.
#
# Dict values above are NOT MERGED with the values here: anything defined here --
# including null! -- fully *overrides* the top-level keys above. So, for example, if you
# defined podAnnotations above and want to augment read-only pods with one additional
# annotation, you'll need to fully redefine all the same podAnnotations here too, because
# the chart won't merge them.
readonly:
  # Set a value greater than zero to enable read-only nodes. A separate K8s Service
  # (suffixed with "readonly") is created to serve as an endpoint for read-only queries.
  replicaCount: 0
  # All other keys will fully override the voter node configuration above when they are
  # defined (even as null) here.


# The config section offers more convenient abstractions for aspects of rqlite
# configuration.
#
# If you need some capability not provided here, it may be possible to accomplish using
# extraArgs, extraEnv, and/or extraFiles above. However, if the feature you need is
# available in this section, it's *strongly* recommended you enable it here, because other
# functionality of the Helm chart may depend on it.
#
# These values apply to all types of nodes (voters and read-only alike).
config:
  tls:
    # TLS configuration for inter-node communication.
    #
    # https://rqlite.io/docs/guides/security/#node-to-node-encryption
    #
    # Tip: for certificates/keys offered as chart values, use YAML's block scalar '|'
    # indicator to hold multi-line strings. For example:
    #     cert: |
    #       -----END CERTIFICATE-----
    #       [...]
    #       -----BEGIN CERTIFICATE-----
    node:
      # If true, inter-node TLS will be enabled. Note that rqlite doesn't support mixed
      # mode operation, so toggling this flag will require taking downtime by first
      # scaling the number of replicas down to 0 and then upgrading the Helm chart
      # with the new value(s).
      enabled: false
      # Name of a native kubernetes.io/tls type Secret in the same namespace that
      # holds the node's certificate. The secret must be created outside the chart in the
      # same namespace. To specify a certificate via the chart, see the "cert" and "key"
      # fields below.
      secretName: null
      # This is a server name that must appear in the node certificate SAN list in order
      # to pass certificate verification when one node connects to another, for example
      # rqlite.db.svc.cluster.local. If 'enabled' above is true, then this *must* be set
      # or the chart will error.
      #
      # This is because rqlite nodes in the cluster are discovered via DNS, and
      # connections are then established to the pod IPs, but pod IPs are unpredictable
      # (unless you leverage special constructs like Calico IP Pools). This setting allows
      # provisioning the certificate with a well-known SAN which can be verified.
      #
      # If for some reason you want to disable this and force chart deployment anyway,
      # set this value to the empty string ("") instead of null.
      verifyServerName: null
      # If true, mutual TLS is enabled using the node's certificate as both client and
      # server cert. No SAN verification is done on the client cert, so any certificate
      # issued by a known CA will be trusted. Consequently this is not a replacement
      # for password-based authentication (see config.users below), but can be used to
      # augment it.
      mutual: false
      # Disable all certificate verification for inter-node connections. This is
      # obviously discouraged but it can be useful for testing.
      insecureSkipVerify: false
      # Server certificate in PEM format. Include all intermediate CA certificates here,
      # if applicable. This is ignored if secretName is defined.
      cert: ""
      # Server private key in PEM format. This is ignored if secretName is defined.
      key: ""
      # Optional PEM-formatted root CA certificate(s) used to validate certificates
      # presented by other nodes. If not defined, the system's default trust store will be
      # used. Mandatory if using a non-public CA. Multiple PEM certificates may be
      # concatenated in this string to trust more than one authority.
      #
      # This value is unused if "mutual" above is false.
      ca: ""
      # As an alternative to directly specifying the CA certificates in the "ca" field
      # above, the CA(s) can be sourced from a Kubernetes Secret. The Secret must be
      # pre-created in the same namespace, must contain a key "ca.crt" whose value is in
      # PEM format.
      #
      # For example, if using cert-manager to generate certificates, some issuer types
      # will include a ca.crt field in the Secret holding generated certificate. In this
      # scenario, because rqlite uses the same certificate for both server and client
      # certificates when mutual TLS is enabled, you may find it convenient to use the
      # same Kubernetes Secret as "secretName" above.
      #
      # This value takes precedence over "ca" if defined, and is unused if "mutual" above
      # is false.
      caSecretName: null

    # TLS configuration for clients of the HTTP API.
    #
    # https://rqlite.io/docs/guides/security/#https-api
    client:
      # If true, the Kubernetes Service will present an HTTPS interface on port 443
      # (or service.port if you explicitly set it above).
      enabled: false
      # As with config.tls.node.secretName, but only affecting the client-facing port.
      secretName: null
      # If true, the client will be required to present a TLS client certificate.
      # The required root CA for the client's cert can be defined in "ca" below.
      #
      # XXX: currently ignored due to https://github.com/rqlite/rqlite/issues/1508
      mutual: false
      # Server certificate in PEM format. Include all intermediate CA certificates here,
      # if applicable. This is ignored if secretName is defined.
      cert: ""
      # Server private key in PEM format. This is ignored if secretName is defined.
      key: ""
      # Optional root CA certificate used to validate certificates presented by clients
      # when mutual TLS is in use. If not defined, the system's default trust store will
      # be used.
      ca: ""
      # As an alternative to directly specifying the CA certificates in the "ca" field
      # above, the CA(s) can be sourced from a Kubernetes Secret. The Secret must be
      # pre-created in the same namespace, must contain a key "ca.crt" whose value is in
      # PEM format.
      #
      # This value takes precedence over "ca" if defined, and is unused if "mutual" above
      # is false.
      caSecretName: null


  # When the users array is defined, HTTP basic authentication is enabled on rqlite. The
  # YAML map below is JSONified directly with the structure you specify here, so it must
  # conform to rqlite's requirements as described at:
  #
  # https://rqlite.io/docs/guides/security/#configuring-usernames-and-passwords
  #
  # Two additional internal systems users will be automatically created by the chart with
  # randomly generated passwords: one used for Kubernetes health probes, and one for
  # rqlite itself used for internode-communication.
  #
  # By default the users list is empty, which means no authentication is enabled on
  # rqlite. Beware that in this case anyone who can reach it over the network has full
  # privileges.
  #
  # rqlite does not currently support dynamically reloading of this file when it changes
  # on disk, so you will need to do a rolling restart after updating.
  users: []
  #  - username: myapp
  #    password: 9uyYgs2NugvpSrEcZCmsu4mYdm1FBPZ9
  #    perms: [execute, query]

  # This section configures rqlite's automatic backup/restore functionality, which supports
  # S3-compatible cloud storage providers.
  #
  # See also https://rqlite.io/docs/guides/backup/
  #
  # Be aware that apart from the "enable" field, any other change will require a
  # rolling restart of rqlite to pick up the changes.
  backup:
    # The storage map describes the S3 bucket that applies to both backups and restores
    # (if either is enabled).
    storage:
      # These are the credentials used to access the bucket.
      accessKeyId: ""
      secretAccessKey: ""
      # The S3 endpoint URL is optional when using native Amazon S3, but for non-Amazon
      # providers such as Wasabi, Backblaze B2, or self-hosted solutions like MinIO, you
      # will need to specify it.
      #
      # HTTPS is assumed if no URL scheme is given, so in most cases you can just specify
      # the FQDN here, e.g. "s3.eu-central-1.wasabisys.com". However if non-SSL HTTP is
      # required, for example with self-hosted MinIO on the same network, you can prefix
      # the endpoint with http://
      endpoint: null
      # The name of the S3 bucket backups are written to (or pulled from)
      bucket: rqlite-bucket
      # The region of the S3 bucket.  With MinIO this is usually just "us-east-1"
      region: us-east-1
      # Full path and object name of the backup file
      path: backups/rqlite.sqlite.gz
    autoBackup:
      # Whether to enable automatic backups
      enabled: false
      # Backup frequency. This is a duration string as defined at
      # https://pkg.go.dev/maze.io/x/duration#ParseDuration
      interval: 1h
      # Whether to run a VACUUM on the SQLite database prior to exporting for backup.
      # This requires having sufficient free disk space.  See also
      # https://www.sqlite.org/lang_vacuum.html
      vacuum: false
      # Normally backups are compressed prior to uploading. Set to true to disable
      # compression.
      noCompress: false
      # If true, a timestamp will be prepended to the last element of storage.path above.
      # This provides an alternative to enabling versioning on the bucket, which may be
      # useful in cases where your object storage doesn't offer sufficient WORM semantics
      # with bucket versioning alone.
      #
      # As with bucket versioning, you will likely want to configure a lifecycle policy on
      # the bucket to age out old backups.
      timestamp: false
    autoRestore:
      # Whether to enable automatic restoration on startup. This will only occur when the
      # PV has no existing data, and only by the elected rqlite leader.
      enabled: false
      # How long to wait for backup files to be downloaded from cloud storage before
      # giving up. Note this isn't related to network timeouts or download stalls: this
      # applies equally to successful downloads as well. For larger data sets, you may
      # want to increase this from the chart default.
      timeout: 5m
      # By default, download failures (including timeouts) will cause rqlite to exit, and
      # the pod will be restarted. Set this to true if you want rqlite to continue startup
      # despite a download failure.
      continueOnFailure: false

  # This section configures rqlite's Change Data Capture (CDC) functionality, which allows
  # streaming change events to an HTTP endpoint.
  #
  # See also https://rqlite.io/docs/guides/cdc/
  #
  # CDC can only be enabled on voting nodes.
  #
  # Note: CDC requires rqlite v9.0.0 or later.
  cdc:
    # If true, CDC will be enabled. When enabled, the 'endpoint' field must be set.
    enabled: false
    # The HTTP endpoint to which CDC events are sent. This is required when CDC is enabled.
    # Can be an HTTP or HTTPS URL, e.g. "https://cdc-consumer.example.com/events"
    endpoint: ""
    # Optional service ID to differentiate events from multiple rqlite clusters.
    # If set, this value will be included in each CDC event.
    serviceId: ""
    # If true, only row IDs will be sent in CDC events, not the full row data.
    rowIdsOnly: false
    # Optional regular expression to filter which tables changes are captured for.
    # If not specified, changes to all tables are captured.
    # Example: "^(users|orders)$" would only capture changes to users and orders tables.
    tableFilter: ""
    # TLS configuration for connecting to the CDC endpoint.
    tls:
      # Path to CA certificate file for TLS verification (mounted via extraFiles).
      caCertFile: ""
      # Path to client certificate file for mutual TLS (mounted via extraFiles).
      certFile: ""
      # Path to client private key file for mutual TLS (mounted via extraFiles).
      keyFile: ""
      # If true, TLS certificate verification will be skipped. Not recommended for production.
      insecureSkipVerify: false
      # Server name to verify in the certificate. If empty, the hostname from the endpoint is used.
      serverName: ""
    # Maximum number of events to send in a single request to the endpoint.
    maxBatchSize: 10
    # Maximum delay before sending a batch to the endpoint, regardless of batch size.
    # This is a duration string (e.g., "200ms", "1s", "5m").
    maxBatchDelay: "200ms"
    # Interval at which the high watermark is broadcast by the leader.
    # This is a duration string (e.g., "1s", "5s").
    highWatermarkInterval: "1s"
    # Timeout for transmitting events to the endpoint.
    # This is a duration string (e.g., "5s", "30s").
    transmitTimeout: "5s"
    # Maximum number of retries for sending events. If null, events will be retried forever.
    transmitMaxRetries: null
    # Retry policy: "linear" or "exponential". Linear uses constant backoff, exponential
    # increases the delay exponentially with each retry.
    transmitRetryPolicy: "linear"
    # Initial backoff time for retries. This is a duration string (e.g., "1s", "5s").
    transmitMinBackoff: "1s"
    # Maximum backoff time for exponential retry policy. This is a duration string (e.g., "30s", "5m").
    transmitMaxBackoff: "30s"
